<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aran's Hall of E-certificates</title>
    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700&family=Playfair+Display:wght@500;600;700&display=swap" rel="stylesheet">
    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="STI.css">
    <link rel="icon" type="image/png" href="images/certicon.png">
    <style>
        /* Adding styles for paragraph indentation and justification */
        .modal-certificate-reflection p {
            text-align: justify;
            text-indent: 2em;
            margin-bottom: 1em;
        }
    </style>
</head>
<body>
    <!-- Header Section -->
    <header>
        <div class="header-bg">
            <div class="particles" id="particles"></div>
        </div>
        <div class="header-container">
            <div class="profile-container">
                <img src="images/aran.jpg" alt="Aran Joshua P. Ofracio" class="profile-pic" id="profilePic">
            </div>
            <h1>Aran's Hall of E-certificates</h1>
            <div class="subtitle">Aran Joshua P. Ofracio</div>
            <div class="subject-info">BSIT 2A Student • Bicol University Polangui • Special Topics in IT</div>
        </div>
    </header>
    
    <!-- Certificate Showcase Section -->
    <section class="certificates-container">
        <div style="text-align: center; margin-bottom: 3rem;">
            <h2 class="section-title">My Certificates Collection</h2>
        </div>
        
        <div class="certificates-grid">
            <!-- Certificate 1 -->
            <div class="certificate-card" data-id="1">
                <div class="certificate-img-container">
                    <img src="images/cert1.jpg" alt="Certificate 1" class="certificate-img">
                </div>
                <div class="certificate-content">
                    <h3 class="certificate-title">Exploring Quantum Computing: A Glimpse to into the Future of Tech</h3>
                    <p class="certificate-reflection">Exploring quantum computing gave me a new perspective on where technology is headed. I learned how concepts like qubits and superposition might shape the future and why they matter even to students like me.</p>
                    <button class="view-certificate">View Certificate</button>
                </div>
            </div>
            
            <!-- Certificate 2 -->
            <div class="certificate-card" data-id="2">
                <div class="certificate-img-container">
                    <img src="images/cert2.jpg" alt="Certificate 2" class="certificate-img">
                </div>
                <div class="certificate-content">
                    <h3 class="certificate-title">Generative AI for Youth</h3>
                    <p class="certificate-reflection">Learning about AI in a more grounded, honest way changed how I see its role in my future. What once felt overwhelming now feels like a challenge I’m actually excited to take on.</p>
                    <button class="view-certificate">View Certificate</button>
                </div>
            </div>
            
            <!-- Certificate 3 -->
            <div class="certificate-card" data-id="3">
                <div class="certificate-img-container">
                    <img src="images/cert3.jpg" alt="Certificate 3" class="certificate-img">
                </div>
                <div class="certificate-content">
                    <h3 class="certificate-title">AI for End Users</h3>
                    <p class="certificate-reflection">The session on AI helped me think more critically about how I use tools in my everyday work. It showed me that AI isn’t just about automation but about how we choose to engage with it, whether actively, passively, or somewhere in between.</p>
                    <button class="view-certificate">View Certificate</button>
                </div>
            </div>
            
            <!-- Certificate 4 -->
            <div class="certificate-card" data-id="4">
                <div class="certificate-img-container">
                    <img src="images/cert4.jpg" alt="Certificate 4" class="certificate-img">
                </div>
                <div class="certificate-content">
                    <h3 class="certificate-title">AI for Developers</h3>
                    <p class="certificate-reflection">This webinar helped me gain a clearer understanding of how developers use AI tools in practical ways. This session taught me how to integrate APIs, use pre-trained models, and consider ethical challenges in real-world AI development.</p>
                    <button class="view-certificate">View Certificate</button>
                </div>
            </div>
            
            <!-- Certificate 5 -->
            <div class="certificate-card" data-id="5">
                <div class="certificate-img-container">
                    <img src="images/cert5.jpg" alt="Certificate 5" class="certificate-img">
                </div>
                <div class="certificate-content">
                    <h3 class="certificate-title">Turning Social Impact Services into a Product with AI</h3>
                    <p class="certificate-reflection">Reflecting on the Eskwelabs webinar reshaped how I view AI, not just as a tool for efficiency but as a way to build meaningful, community-driven impact through thoughtful and inclusive design.</p>
                    <button class="view-certificate">View Certificate</button>
                </div>
            </div>
            
            <!-- Certificate 6 -->
            <div class="certificate-card" data-id="6">
                <div class="certificate-img-container">
                    <img src="images/cert6.jpg" alt="Certificate 6" class="certificate-img">
                </div>
                <div class="certificate-content">
                    <h3 class="certificate-title">AI for Beginners</h3>
                    <p class="certificate-reflection">Studying artificial intelligence has made me question who it really serves and pushed me to notice the subtle, often overlooked ways it’s already shaping daily life in my own context.</p>
                    <button class="view-certificate">View Certificate</button>
                </div>
            </div>
            
            <!-- Certificate 7 -->
            <div class="certificate-card" data-id="7">
                <div class="certificate-img-container">
                    <img src="images/cert7.jpg" alt="Certificate 7" class="certificate-img">
                </div>
                <div class="certificate-content">
                    <h3 class="certificate-title">Introduction to Cybersecurity</h3>
                    <p class="certificate-reflection">I used to think digital threats were rare and mostly targeted people who made obvious mistakes. But after learning how common and quiet some risks are (especially ones tied to stress, shortcuts, and tired decisions) I started seeing cybersecurity less as tech jargon and more as a daily habit I’d been ignoring.</p>
                    <button class="view-certificate">View Certificate</button>
                </div>
            </div>
            
            <!-- Certificate 8 -->
            <div class="certificate-card" data-id="8">
                <div class="certificate-img-container">
                    <img src="images/cert8.jpg" alt="Certificate 8" class="certificate-img">
                </div>
                <div class="certificate-content">
                    <h3 class="certificate-title">What is Generative AI?</h3>
                    <p class="certificate-reflection">Exploring generative AI gave me a clearer sense of how technology shapes the world we live in by showing me that understanding the layers beneath the surface is just as important as using the tools themselves.</p>
                    <button class="view-certificate">View Certificate</button>
                </div>
            </div>
            
            <!-- Certificate 9 -->
            <div class="certificate-card" data-id="9">
                <div class="certificate-img-container">
                    <img src="images/cert9.jpg" alt="Certificate 9" class="certificate-img">
                </div>
                <div class="certificate-content">
                    <h3 class="certificate-title">Generative AI: The Evolution of Thoughtful Online Search</h3>
                    <p class="certificate-reflection">This course made me realize that asking clear, thoughtful questions is key to getting the best results from generative AI. It shifted my focus from quick answers to more intentional, refined thinking.</p>
                    <button class="view-certificate">View Certificate</button>
                </div>
            </div>
            
            <!-- Certificate 10 -->
            <div class="certificate-card" data-id="10">
                <div class="certificate-img-container">
                    <img src="images/cert10.jpg" alt="Certificate 10" class="certificate-img">
                </div>
                <div class="certificate-content">
                    <h3 class="certificate-title">The Cybersecurity Threat Landscape</h3>
                    <p class="certificate-reflection">This course highlighted how attackers are using smarter, more personal tactics, and how our carelessness can make us easy targets. It shifted my view on cybersecurity from a technical issue to a mindset I need to adopt in my own habits.</p>
                    <button class="view-certificate">View Certificate</button>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Certificate Modal -->
    <div class="modal" id="certificateModal">
        <div class="modal-content">
            <div class="close-modal" id="closeModal">
                <i class="fas fa-times"></i>
            </div>
            <img src="/api/placeholder/800/500" alt="Certificate" id="modalCertificateImg" class="modal-certificate-img">
            <h3 class="modal-certificate-title" id="modalCertificateTitle">Certificate Title</h3>
            <div class="modal-certificate-reflection" id="modalCertificateReflection">
                Certificate reflection will appear here.
            </div>
        </div>
    </div>
    
<!-- Updated Author's Note Section with Interactive Elements --> 
<section class="authors-note-section"> 
<div class="authors-note-container"> 
    <div class="authors-note-header"> 
        <h2>Aran's Personal Note</h2> 
        <div class="authors-note-divider"></div> 
    </div> 
    <div class="authors-note-content"> 
        <div class="authors-note-icon"> 
            <i class="fas fa-quote-left"></i> 
        </div> 
        <div class="authors-note-text"> 
            <p class="indented-paragraph">After finishing all ten webinars and courses, there's something that really stood out to me. Most of the speakers were in their 30s to 50s, and it became kind of predictable after a while. They'd talk about things like AI, automation, the metaverse, blockchain, and all that stuff with this huge sense of excitement, like they just uncovered some big secret. And I kept thinking, "Wait… that's it?" Because to me, a lot of it felt like stuff I already knew.</p>
            
            <p class="indented-paragraph">Maybe it's a generational thing. Like yeah, I respect their experience and all, but it's kind of funny how they explain basic concepts like algorithms or digital trends as if they're mind-blowing discoveries. I get that for them, these shifts are massive and maybe even a bit overwhelming. But for people like me who basically grew up surrounded by tech, it's just our normal. It's not some wild new future, we've been living in it.</p>
            
            <p class="indented-paragraph">I'm not trying to sound condescending in any way. I do appreciate the effort they put into these sessions, and I still picked up a few cool ideas. But I couldn't ignore how different their approach was. They were talking about adapting to new tech, while I was thinking, "We've already adapted." For our generation, it's not something we had to learn later on, it's just how things have always been.</p>
            
            <p class="indented-paragraph">So after writing all ten reflections, I kinda had this moment where I was like, "Wait, maybe we actually do have something valuable to bring to the table." People my age, we don't have stacked resumes or decades of experience, but we see things differently, and that's not a bad thing. We're not scrambling to keep up with tech because we've grown up with it. It's part of how we think, how we create, how we solve problems. That perspective matters more than I thought it did.</p>
            
            <p class="indented-paragraph">Even if a bunch of the webinars felt repetitive or dragged on a bit, I'm still glad I went through all of them. It gave me a clearer picture of how older generations approach tech, and it made me more aware of how different my default way of thinking actually is. </p>
        </div> 
    </div> 
</div> 
</section>

    <!-- Footer Section -->
    <footer>
        <div class="footer-content">
            <p class="footer-text">Final Project for Special Topics in IT under Ma'am Khristine Botin</p>
            <p class="copyright">© 2025 Aran Joshua P. Ofracio | BSIT 2A - Bicol University Polangui</p>
        </div>
    </footer>
    

    
    <script>
        // Create floating particles
        document.addEventListener('DOMContentLoaded', function() {
            const particlesContainer = document.getElementById('particles');
            const numberOfParticles = 30;
            
            for (let i = 0; i < numberOfParticles; i++) {
                const particle = document.createElement('div');
                particle.classList.add('particle');
                
                // Random position, size and animation delay
                const size = Math.random() * 5 + 2;
                particle.style.width = `${size}px`;
                particle.style.height = `${size}px`;
                particle.style.left = `${Math.random() * 100}%`;
                particle.style.top = `${Math.random() * 100}%`;
                particle.style.opacity = `${Math.random() * 0.5 + 0.1}`;
                particle.style.animationDelay = `${Math.random() * 8}s`;
                particle.style.animationDuration = `${Math.random() * 12 + 8}s`;
                
                particlesContainer.appendChild(particle);
            }
            
// Profile picture animation - more interesting hover effect
const profilePic = document.getElementById('profilePic');

profilePic.addEventListener('mouseover', function() {
    this.style.transition = 'all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275)';
    this.style.transform = 'scale(1.08)';
    this.style.boxShadow = '0 10px 20px rgba(0,0,0,0.25)';
    this.style.filter = 'brightness(1.1)';
    this.style.border = '3px solid #3498db';
});

profilePic.addEventListener('mouseout', function() {
    this.style.transition = 'all 0.3s ease';
    this.style.transform = 'scale(1)';
    this.style.boxShadow = '0 0 0 rgba(0,0,0,0)';
    this.style.filter = 'brightness(1)';
    this.style.border = '1px solid transparent';
});
            
            // Certificate data
            const certificatesData = [
                {
                    id: 1,
                    title: "Exploring Quantum Computing: A Glimpse to into the Future of Tech",
                    reflection: "<p>The first time I encountered quantum computing, it was buried somewhere in our Platform Technologies class—a slide or two, quickly glossed over, with terms like qubits, entanglement, and superposition that sounded more like theoretical physics than anything meant for IT majors like me. At the time, it felt more like trivia than anything I'd actually engage with. But taking Exploring Quantum Computing: A Glimpse into the Future of Tech challenged that sense of distance. It didn't hand me all the answers, but it made quantum feel less like a foreign language and more like a language I could, eventually, start learning.</p><p>There's a kind of pressure that comes with studying tech in a country like ours. You're constantly reminded that the tools you're working with are at least a generation behind, that much of the world is already two steps ahead, and that global conversations about innovation rarely center us. So when the course opened up ideas about quantum's potential to accelerate problem-solving, revolutionize machine learning, or break encryption as we know it, I felt a mix of excitement and dread. Part of me thought, this is incredible. Another part thought, We're not ready for this. Not just in terms of hardware or funding, but even in terms of how we teach students to think. Quantum computing doesn't just ask us to upgrade our systems; it asks us to upgrade our assumptions. That's a much harder fix.</p><p>In a country where government websites still get hacked by teenagers, where a lot of people reuse the same password for everything, and where data privacy laws feel more symbolic than enforced, it's hard not to imagine how fragile our systems would be in a post-quantum world. If quantum computers can eventually break current encryption standards in minutes, what happens to entire sectors that are already struggling to digitize securely? It's not even a far-future problem anymore. The race to develop quantum-resistant algorithms has already started. Watching that unfold from the outside, as someone who isn't yet in the industry but wants to be, is both humbling and a little terrifying.</p><p>Still, the course wasn't just a warning, it was also an invitation. Quantum computing may not be accessible to me right now, but understanding its direction helps me position myself. I started researching what countries in Southeast Asia are doing in this space, and while we're definitely trailing, there are pockets of movement. It made me rethink what kind of tech career I want to build. I used to picture myself doing app development or data science, which is something stable, concrete, and safe. But now I'm thinking more about what it means to work at the edges of things, even if it means being confused for longer. Maybe our generation won't build the next IBM Q System, but we'll need translators, communicators, and problem-solvers who can bring these ideas down to the level of real-world problems, especially here at home.</p><p>A lot of the math still confuses me. Some parts I had to replay multiple times just to grasp the framing. But I left with something more durable than understanding: curiosity, grounded in context. Not the kind that romanticizes the future of tech blindly, but the kind that asks, what does this mean for where I live? For the people around me? For the kind of technologist I want to become?</p>",
                    imgUrl: "images/cert1.jpg"
                },
                {
                    id: 2,
                    title: "Generative AI for Youth",
                    reflection: "<p>I'll be honest, I signed up for Koenig's AI webinar mostly just to get the certificate. I wasn't expecting much. I figured it would be another generic online session filled with recycled slides, monotone voices, and the same predictable examples about how AI is changing the world. I was ready to tune out, grab the cert, and move on with my day. But this one actually caught me off guard in a good way.</p><p>From the start, the speaker felt different. Instead of talking at us, they talked to us, like we were real people with thoughts and opinions, not just passive students staring blankly at screens. The tone was conversational, not condescending. It didn't feel like a lecture; it felt like someone pulling up a chair and saying, \"Let's talk about this thing we're all trying to figure out together.\"</p><p>What really stood out was how balanced and grounded the discussion was. No fearmongering about AI stealing every job, and no exaggerated promises that it's going to save the world either. Just an honest look at what AI is, what it can do, and what it can't do (at least not yet). They acknowledged how AI can generate essays in seconds, create artwork with a few prompts, even write code faster than most beginners. But instead of making it sound like a threat or a miracle, the speaker framed it as a challenge: what does that mean for students like us, who are just starting to shape our paths? That really hit me. We're constantly being told to either fear AI or bow down to it. But no one really talks about what it means to live and work with it. The speaker compared AI to something like a hammer, a powerful tool, but only as good or bad as the person using it. That stuck with me. It made AI feel less like this all-knowing entity and more like just another part of the toolbox we're going to need to learn how to use.</p><p>As someone who is actually passionately studying IT and not just because my parents told me so, I already know how quickly things move. One day I'm learning C++, and the next I hear people saying \"AI can code better than you now.\" It's overwhelming. During the Q&A, someone even asked whether software developers will still have jobs in ten years. The speaker didn't dodge the question or offer a fake reassuring answer. Instead, they said something that really made sense, that the tedious, repetitive stuff might go away, but we'll still need people who can ask smart questions, think critically, and guide the tools in the right direction. AI can generate code, sure, but it can't understand why something needs to be built, or whether it should be. That gave me some peace of mind. I don't need to be some sort of out of this world coder. I just need to stay curious, stay flexible, and keep learning. That mindset felt way more realistic and less terrifying than trying to \"beat\" AI somehow.</p><p>I won't lie, there were moments in the webinar that stressed me out. The speaker mentioned tools like OpusClip and Midjourney, things I had heard of but never actually used. I started scribbling down names, feeling a bit panicked at how much I still don't know. But at the same time, I liked the honesty. No sugarcoating, no pretending like we've got time to sit back and wait. The reality is, technology moves whether we're ready or not. Either we move with it, or we fall behind. Harsh, but fair.</p><p>After the session ended, I just sat there for a while, thinking. I'm not the best coder out there (not yet, at least). My portfolio's not as impressive as I want it to be. But I care. I'm interested. And maybe that's enough for now, just enough to get started. Since then, I've been experimenting with a few AI tools, nothing major, just exploring what's out there. Even that little bit has already shifted my mindset. I no longer see AI as some sort of cheat code, but more like a new language I need to learn if I want to stay relevant.</p><p>The webinar didn't magically give me all the answers. But it gave me a better question: Where do I want to fit in this new world? And I think that's a way more useful thing to walk away with. Honestly, being young in tech right now might be more of a blessing than a burden. We're not just watching change happen, we're in a position to help shape it. The future isn't something we just react to. It's something we help build. One smart decision at a time.</p>",
                    imgUrl: "images/cert2.jpg"
                },
                {
                    id: 3,
                    title: "AI for End Users",
                    reflection: "<p>I showed up to the AI for End Users webinar expecting background noise. I've sat through enough of these sessions to know how they usually go. Surface-level intros, tool demos I've already heard of, and maybe a quote about the future of work. What I didn't expect was to actually start paying attention while I was multitasking it with my work. Not because it was exciting or revolutionary, but because it was... quietly useful.</p><p>They weren't trying to oversell AI or scare anyone. They just laid things out plainly, like how AI is already part of normal work routines and how that's not some far-off scenario, it's happening now. It made me think about how I've been using AI: a bunch of tools I try, copy results from, and move on. I hadn't really thought about what that says about my learning process, or lack of one.</p><p>The webinar framed AI as something that amplifies your current habits. If you're curious, it pushes you further. If you're passive, it makes you even more passive. That idea stuck because it kind of called me out. I realized I've been heavily reliant on AI with my work especially in translations and data collection. I grab what I need, move faster, avoid thinking too hard. But now I'm wondering: is that making me sharper or just lazier?</p><p>One thing I valued was how grounded everything was. They didn't show off flashy models or mention disruption every five minutes. They talked about AI being used in very normal ways like through automating emails, summarizing meetings, helping draft internal reports. Nothing dramatic, but that's the point. These tools are slipping into places we don't even notice. That's what makes them powerful. And slightly dangerous.</p><p>A question came up during Q&A that I related to since I've worked in several different fields in the last 5 years: What if AI replaces the entry-level jobs we're working toward? It's a valid fear, and I've asked myself the same thing (there was actually a message by my deputy in our work group chat where she said that management is utilizing AI a lot for translations recently, so that kind of put me at unease). The answer was more strategic than comforting. They said it's not about protecting job titles, it's about adapting skills. If your value is tied to doing something repetitive, yeah, that job might fade. But if you know how to think through a problem, how to use tools without blindly trusting them, you're going to be fine. Not because you're special, but because you're not sleepwalking through your work.</p><p>I didn't walk away from the webinar with some kind of life-changing epiphany. If anything, it just helped me articulate things I've already been doing. I've always been the type to double-check AI's outputs, tweak what it gives me, and use it more like a sparring partner than a shortcut. The session didn't teach me something brand new, but it helped me put into words what I've already been practicing. I realized it's not about being some kind of AI power user. It's just about staying sharp by questioning, adjusting, not zoning out and blindly accepting whatever the tool spits out. That kind of back-and-forth isn't extra effort; it's the whole point.</p><p>This doesn't mean I suddenly know everything or that I've become hyper-productive. It just means I've started becoming better at using the power of artificial intelligence. And I think that's what most people miss when they talk about AI: the tools don't matter as much as the mindset behind how you use them. That's what the webinar did for me, not blow my mind, but adjust the way I think about thinking.</p>",
                    imgUrl: "images/cert3.jpg"
                },
                {
                    id: 4,
                    title: "AI for Developers",
                    reflection: "<p>I joined the \"AI for Developers\" webinar by Koenig with a very specific intention: to fill a noticeable gap in my understanding. As an IT student, I've taken the usual route through data structures, object-oriented programming, and the occasional machine learning crash course. But something about AI from a developer's perspective (beyond the hype, and more focused on real-world utility) had always felt just out of reach. So when I saw this session offered through Koenig, it wasn't just about getting another e-certificate to decorate a resume. I wanted to hear how developers, not researchers, were using AI tools in the trenches.</p><p>The session itself was surprisingly grounded. There was no robotic voice claiming AI would \"change everything,\" and no futuristic predictions about machines taking over. Instead, the speaker laid out a developer-centric roadmap: APIs, low-code frameworks, model integration, and the tricky balance between off-the-shelf tools and custom solutions. One part that stuck with me was a brief segment on using pre-trained models through TensorFlow Hub and Hugging Face. I'd read those names before, mostly in documentation I skimmed while debugging things late at night, but seeing them used in such accessible workflows gave me a clearer picture.</p><p>What I also appreciated was how the speaker didn't assume we were beginners, but also didn't assume we were already deploying massive systems. They seemed to know exactly where most students and early-career developers are mentally stuck, somewhere between understanding how AI works in theory and actually building something useful with it. There was a short walkthrough involving a sentiment analysis model, and while it was nothing revolutionary, it helped to see the end-to-end pipeline compressed into something that could be done in an afternoon. It was use-first, then understand deeper as needed. I like that order better.</p><p>There was also a discussion on ethical challenges, though it didn't take the usual \"AI is scary\" route. The speaker framed it as a developer's responsibility, not just an academic debate. If you're deploying a chatbot, are you thinking about who it's trained on? If you're building a recommendation engine, have you tested it beyond just your own dataset? It made me think about a recent side project I did for a client's small business, where I used a basic AI plugin to handle customer responses (most of the data came from my experience as a customer service agent for MLBB). At the time, I was just proud it worked. Now, I'm wondering what blind spots I introduced without realizing. That's not the kind of lesson you get from tutorials, it only comes from engaging with people who've built these systems, failed a few times, and learned through it.</p><p>In the end, what I took from this webinar wasn't a list of new tools, but a clearer sense of what it means to be a developer with AI, not just a developer using AI. The e-certificate is nice, sure, but more importantly, I left the session with a slightly upgraded mindset. I still don't have all the answers, but I'm fine with that. And for a short webinar on a Thursday afternoon, that's more than I expected.</p>",
                    imgUrl: "images/cert4.jpg"
                },
                {
                    id: 5,
                    title: "Turning Social Impact Services into a Product with AI",
                    reflection: "<p>There's a sort of pressure that comes with being someone in tech. People expect you to build things fast, clean, and scalable. There's a kind of thrill in that, sure, but also a risk of becoming detached. Detached from the people you're supposedly designing for. Detached from the messiness of real-world problems. That's why the Eskwelabs webinar on turning social impact services into products with AI felt like a reset. It wasn't about showing off the latest tools or hyping up abstract promises. It asked much harder questions: What makes a project truly useful? Who benefits? Who gets left out? And how can emerging tech like AI serve people in ways that actually matter?</p><p>What stood out to me immediately was how they framed the intersection of social impact and product thinking. In tech, we're used to talking about \"users,\" \"solutions,\" \"pain points,\" as if we're fixing a broken system with elegant lines of code. But social impact work rarely follows that logic. It's messy, unpredictable, and deeply human. The session challenged the idea that social services should stay as one-off efforts or charity work. Instead, it offered a more practical and sustainable perspective: that services rooted in impact can and should be treated like products. Not for profit, necessarily, but for longevity and clarity.</p><p>As someone deeply interested in emerging tech, I've always gravitated toward AI as something powerful. But the more I study it, the more I realize it's not powerful by default. It reflects the intent of whoever builds it. The webinar didn't treat AI like a silver bullet. Instead, it was introduced as a kind of amplifier, something that can help scale a solution, analyze trends, make processes smarter. But that only happens when it's used with care. They shared examples of using AI to map community needs, track which groups are underserved, and even predict where support might break down. So long story short, most of the AI content I usually see revolves around automation or convenience. Rarely do people talk about it as a tool for equity or inclusion.</p><p>I started thinking about how disconnected some of my own projects have been. I've played around with machine learning models, built prototypes for class or freelance work, and even joined hackathons where we had to \"solve\" big problems in under 48 hours. But looking back, I can't say any of it had much staying power. It's easy to build fast and leave. Much harder to build slow and stick with the consequences. The webinar emphasized co-creation by working with communities, not just for them, and that idea keeps circling back in my head. Not just \"Can we build this?\" but \"Should we?\" and \"With whom?\"</p><p>Another thing I loved was the honesty about friction. One speaker mentioned that integrating AI into social services doesn't always work smoothly. There's a learning curve. There's resistance. Sometimes there are language and accessibility gaps. But instead of presenting that as failure, they framed it as part of the process. I found that refreshing. In tech, we often treat friction as something to eliminate, but in social work, friction can be where the real understanding starts. It means people are reacting, asking questions, pushing back. And maybe that's a sign you're building something real, not just functional.</p><p>The whole session made me rethink how I view \"impact\" in relation to innovation. Emerging technology isn't good just because it's new. It's good when it fills real gaps. When it empowers people who usually get ignored. That's the version of tech I want to be part of. Not the flashy startup pitch kind, but the slow, deliberate, and human-centered kind.</p><p>Since I'm going to work in tech, especially in something as influential as AI, I can't afford to stay neutral. Tools reflect values. Products reflect priorities. And impact, if I'm serious about it, needs more than code. It needs context, conversation, and commitment. This isn't something I can pin on a resume or summarize in a GitHub repo. But it's the kind of thinking I want to bring with me, consistently, wherever I end up building next.</p>",
                    imgUrl: "images/cert5.jpg"
                },
                {
                    id: 6,
                    title: "AI for Beginners",
                    reflection: "<p>I was halfway through debugging a poorly written Python exercise as practice for my summer school program this June when I paused the code window to attend the \"AI for Beginners\" webinar from HP Life. It didn't teach anything wildly advanced (I already knew most of the terms from class) but it forced me to zoom out and think about how artificial intelligence is shaping the world I'm preparing to graduate into. And not just in theory, but in the exact places where I live, study, commute, and scroll.</p><p>I used to think of AI the same way I think of calculus proofs—important, but far removed from anything I'd actually use unless required. But during the webinar, I kept noticing how familiar some examples felt. Like when they talked about customer service bots and how they're replacing basic inquiries in banks or e-commerce sites (pretty rough considering I used to work in customer service). That's literally what I dealt with last week when I tried to refund a wrong Lazada order and couldn't reach a real person. Or how most online forms now auto-fill my information before I finish typing. It's not flashy, but it's already there in everyday frustrations and shortcuts.</p><p>When the speaker started explaining how AI systems are trained using massive datasets, I couldn't help thinking about how uneven that data might actually be. I remembered browsing a popular language model demo a few months ago and trying to make it respond in Taglish just for fun. It got confused halfway through the sentence. If tools like that are trained mostly on Western or formal English data, then where does that leave the way most Filipinos actually communicate, which is switching languages mid-sentence, using slang, memes, or even just talking about things specific to our context? It made me wonder if AI tools really \"know\" us, or if we're just being flattened out to fit someone else's version of intelligence.</p><p>The part about jobs didn't feel theoretical either. My relative used to work at a ticketing booth for a certain company. She was laid off when they switched to QR scanning and online bookings. The company called it an upgrade, but no one really explained what she was supposed to do next. Sitting there in the webinar, I realized that some of the tools we admire in class like automated systems, predictive services, and optimization apps can have a real cost for people who never got the chance to shift careers. And that tension, between what's efficient and what's humane, isn't always part of the curriculum.</p><p>These days, when I write code or test an app, I think more about who's being left out, not just in design, but in data, context, and consequence. Before, I used to treat AI as a purely academic topic, something for outputs or my work for foreign clients. But now, it feels closer, messier, and more personal. It's embedded in the way we bank, shop, study, and even apply for jobs. It's here, even if it's somewhat invisible in many spaces.</p><p>This webinar didn't teach me how to build AI systems from scratch. What it gave me instead was a kind of pause, one I didn't know I needed. I'm still figuring out what kind of IT professional I want to become, but now I'm more aware of the power and responsibility that comes with working in this space. Not just to build cool stuff, but to make sure it actually fits the reality of the people around me. That, to me, feels like the harder and more important task.</p>",
                    imgUrl: "images/cert6.jpg"
                },
                {
                    id: 7,
                    title: "Introduction to Cybersecurity",
                    reflection: "<p>There's a strange comfort in thinking digital risks are something other people deal with. Before I took Cisco's Introduction to Cybersecurity, I sort of operated that way, aware that threats existed but not really seeing how any of it applied to me or the people around me. But the course didn't focus on far-off concepts or treat cybersecurity like a career path for elites. It unpacked the ways regular people, especially students like me, are exposed in our everyday routines. It wasn't some dramatic warning about hackers in dark rooms. It was more like holding up a mirror to the careless habits we've normalized like clicking suspicious links in class group chats, sharing passwords without thinking, installing free apps just to access a single PDF.</p><p>The course's section on social engineering felt the most personal. I remembered an incident during our first year, when a student from the unofficial BU Facebook group unknowingly gave away her student portal login after posting a screenshot. Nothing catastrophic happened, but her account was slightly tampered with. At the time, most students treated it as a joke. Now I realize that we just didn't have the language or awareness to understand what had happened. The course explained how attackers target emotions like urgency, fear, and curiosity to manipulate people into giving away access. And the more I thought about it, the more I saw how common that emotional pressure is in our academic life. You're rushing a requirement, looking for a free tool, stressed about deadlines. That's the perfect setup for someone to trick you. The scariest part is that you don't even need to be reckless. You just need to be tired and in a hurry.</p><p>Another thing that hit differently was the gap between our personal awareness and the larger systems we use. The course brought up how even institutions like schools, banks, and small businesses don't always follow best practices. I thought about how our university's registration system crashed during enrollment, and someone joked that it got \"hacked by traffic.\" But what if someone actually did exploit it? We don't get told anything. There's barely any digital transparency in most Philippine systems. You just get locked out or asked to refresh the page and move on. That kind of normalization of failure teaches us not to question security at all. It's hard to build good habits in a culture that treats technical failure as a minor inconvenience instead of a warning sign.</p><p>After finishing the course, I didn't come out wanting to specialize in cybersecurity. But I do approach my digital life with more caution and less passivity. I use stronger, unique passwords now. I check where links come from, especially if they're passed around without context. I even changed the way I talk about online safety with my parents, trying not to sound paranoid, just clear. More importantly, the course made me realize that security isn't just a set of tools. It's a mindset. And as someone studying IT, even if I end up in a different field, I know I'll carry that perspective into whatever I build or manage. Because whether we like it or not, everything we create online comes with risks. The least we can do is stop pretending we're immune.</p>",
                    imgUrl: "images/cert7.jpg"
                },
                {
                    id: 8,
                    title: "What is Generative AI?",
                    reflection: "<p>There's something funny about learning the basics of a thing that's already everywhere. Generative AI is practically on every screen I own like on my phone when I scroll, in the tools I use to edit, and lately, in the conversations I overhear in class. But sitting down for a one-hour LinkedIn Learning course titled *\"What Is Generative AI?\"* felt like pressing pause on all that noise. For once, I wasn't just reacting to the outputs, I was tracing the wires behind them, even if just slightly. It wasn't a deep dive, more like dipping your feet in the current to figure out where the river flows (and with the high heat index and all, I could definitely use a dip in the river haha).</p><p>The course didn't try to drown me in formulas or theories, which I appreciated. It was structured like a friendly walkthrough, the kind you'd wish you had before trying to explain ChatGPT to your tita over dinner. They broke things down in a way that felt neither condescending nor overblown, which is rare. It explained the difference between discriminative and generative models, walked through how these systems \"learn,\" and gave concrete examples without slipping into buzzword territory. At one point, I paused just to rewatch the section on diffusion models. It's one of those topics I'd heard tossed around a lot, especially in AI art circles, but never quite clicked in my head until then. Turns out, there's actual math behind the magic, which sounds obvious now, but it's easy to forget when all you see are polished outputs.</p><p>What surprised me was how much the course made me reflect on how fast we accept tech without understanding it. Like, I've used image generators, messed around with ChatGPT prompts, even had fun making meme-worthy voice clones, but did I really know what was going on? Not really. It reminded me of when I first started learning how to code in first year. I'd copy snippets off what I found on the internet without knowing why they worked, just that they did. This course kind of snapped me out of that habit again. Just because something feels intuitive on the surface doesn't mean it's not sitting on layers of complexity worth learning. And now that I've started to peel back the layers, I'm not sure I'll look at AI the same way again.</p><p>Still, it wasn't all smooth. There were moments when the course felt a bit too brief. I get that it was only an hour-long module, but I found myself pausing, Googling terms, and reading side articles just to fill in the gaps. Honestly, that turned out to be one of the better parts of the experience. It wasn't just passive learning anymore. It was me chasing questions, going down rabbit holes, and finding my own rhythm. One late night I ended up reading a Reddit thread about GPT hallucinations and comparing that to what was said in the course, just because I couldn't stop thinking about the ethical implications. That wasn't in the module, but it wouldn't have happened without it.</p><p>Now, with this certificate saved in my drive and a few new concepts lodged in my head, I feel less like a clueless bystander to the AI wave and more like someone who knows how to read the signs. Not an expert, obviously, but a student who's done the work to start asking better questions. And for me, that's what learning in IT has often been about. It's not always about getting to the answer right away. Sometimes, it's just about knowing what to search next. Generative AI isn't going anywhere, and if it's going to keep shaping the world I live in (and maybe even the job I'll have someday) I want to at least understand what it's made of. Even if that understanding started with a one-hour LinkedIn course on a random weekday.</p>",
                    imgUrl: "images/cert8.jpg"
                },
                {
                    id: 9,
                    title: "Generative AI: The Evolution of Thoughtful Online Search",
                    reflection: "<p>Most people think the power of generative AI sits in how good it is at answering things. This course made me focus on something else entirely: how bad we've gotten at asking. The shift from search engines to conversational AI didn't just make results more accessible, it trained us to care less about the quality of our questions (for example, you could type a prompt with poor grammar on ChatGPT and it would still be understood so people don't put in too much of an effort anymore). That's not a tech problem, it's a thinking problem. And in the middle of thesis work, backlogs, and constant pressure to multitask, I saw myself in that trap more than I wanted to admit.</p><p>There were modules that felt uncomfortably close to habits I didn't notice I had. When I'd write prompts back then during first year, I wasn't really thinking about clarity. I just wanted something that \"worked.\" I'd reuse lazy phrasings like \"Explain this concept in simple terms\" even when I wasn't sure what part I didn't understand. Worse, I'd treat the AI's answer as a replacement for comprehension instead of a tool to build it. I wasn't unaware of it, I just didn't bother challenging it. The course didn't talk down to me about this. It just laid out what happens when you let that kind of thinking pile up. It becomes normal.</p><p>The exercises on iterative prompting pushed me a bit more than I formerly anticipated. Not because they were hard technically, but because they forced me to slow down. Most students here in the Philippines, especially in IT, are taught to optimize everything through time, clicks, code, and output. The last thing we're taught to optimize is the way we ask. But that's what generative AI actually demands. It rewards clarity, not cleverness. It exposed how much of my input was me dodging the thinking part and jumping straight to the solution. I started treating prompts the same way I treat version control: something to debug, refine, and actually read back before pressing enter.</p><p>Since the course, I've been testing this mindset across different projects. For a recent group task, instead of assigning someone to \"handle the research with AI,\" we broke it down into specific, layered questions—fact-checkable, contextual, with sources requested. Not surprisingly, the output improved. But more than that, the group started discussing why we were asking what we were asking. That's not common. In a college setting where everyone's fighting deadlines and scraping together load just to stay online, it's easy to slip into passive work. AI makes that easier. But the course reminded me: convenience without curiosity makes you worse, not faster.</p><p>The course treated thoughtful search not as some luxury of academia, but as a survival skill. In a field where tools change monthly and new terms fly faster than stable updates, asking better questions is one of the few things that won't go obsolete. And now that I've caught myself slipping into bad habits, I'm actually interested in pushing back. Not to be \"deeper\" or more academic about it, but because it makes me sharper. Even if no one sees it. Even if the AI still answers either way.</p>",
                    imgUrl: "images/cert9.jpg"
                },
                {
                    id: 10,
                    title: "The Cybersecurity Threat Landscape",
                    reflection: "<p>I've always kept most of my passwords in a Notes app file, casually labeled \"school stuff,\" stored on a phone I've already almost lost twice. Until this course on the cybersecurity threat landscape, I never really thought of that as anything beyond sloppy. But the more I went through the lessons, the more it became clear that the way I handle my data is part of a much bigger pattern: a kind of normalized carelessness, especially among students like me who are too used to convenience. It's not that we don't know any better, it's that we underestimate how easy it is to become a target when we don't take basic threats seriously.</p><p>What I found relevant wasn't the list of malware types or protocols. It was the framing of how threats have shifted. The course explained how attackers now lean more on psychological tactics than brute force. Phishing, for example, isn't just spam anymore. It's personalized, timed, convincing. I kept thinking about this one time a fake Globe promo almost got my mom to input her SIM details. It came from a local-looking number, even included Filipino phrasing. She was on mobile data, half-asleep, and one wrong tap away from giving everything. The course made me realize how vulnerable we are when we're not paying attention. And it's not because we're dumb, it's because the threats are smarter and more local than we expect.</p><p>Another thing I kept thinking about while watching was how uneven cybersecurity awareness is across social classes. In school, we talk about zero-days and endpoint protection like it's common language, but at home, our neighbors are still typing passwords like \"123456\" on borrowed phones. I've helped my tita reset her Facebook account more times than I can count, each time because she clicked on some link promising a GCash raffle. And these attacks aren't slowing down, they're adapting. The course mentioned how threat actors exploit whatever platform people spend time on, and in the Philippines, that's often Messenger, SMS, or TikTok. The danger doesn't feel foreign. It's right here, sitting in people's inboxes.</p><p>It also made me reflect on how security is treated inside school systems. In one of my majors, we use shared drives and borrowed accounts, and sometimes teachers ask us to send passwords via Messenger. Nobody questions it. When the course talked about how organizations often overlook basic safeguards, I kept thinking, \"Yep, that's literally our setup.\" It's not always about the lack of tools. Sometimes it's about habits and attitudes. And I'm part of that. I've been the groupmate who said \"okay na yan\" when we reused a classmate's login for a server test, just to make things faster. We treat shortcuts like survival, but they secretly become risk patterns.</p><p>Cybersecurity doesn't feel like a niche topic anymore. It feels like something stitched into everything I touch—from school submissions to internship emails to random logins on cracked software. I'm starting to see how casually we expose ourselves, and how that's exactly what attackers rely on. If I plan to build systems someday, I have to stop thinking like a student who's just trying to pass. I need to start acting like someone whose shortcuts have consequences.</p>",
                    imgUrl: "images/cert10.jpg"
                }
            ];
            
            // Certificate modal functionality
            const certificateCards = document.querySelectorAll('.certificate-card');
            const modal = document.getElementById('certificateModal');
            const closeModal = document.getElementById('closeModal');
            const modalCertificateImg = document.getElementById('modalCertificateImg');
            const modalCertificateTitle = document.getElementById('modalCertificateTitle');
            const modalCertificateReflection = document.getElementById('modalCertificateReflection');
            
            // Open modal with certificate details
            certificateCards.forEach(card => {
                card.addEventListener('click', function() {
                    const certificateId = parseInt(this.getAttribute('data-id'));
                    const certificate = certificatesData.find(cert => cert.id === certificateId);
                    
                    if (certificate) {
                        modalCertificateImg.src = certificate.imgUrl;
                        modalCertificateImg.alt = certificate.title;
                        modalCertificateTitle.textContent = certificate.title;
                        
                        // Check if the reflection contains HTML tags
                        if (certificate.reflection.includes('<p>')) {
                            modalCertificateReflection.innerHTML = certificate.reflection;
                        } else {
                            modalCertificateReflection.textContent = certificate.reflection;
                        }
                        
                        // Show modal with animation
                        modal.classList.add('active');
                        document.body.style.overflow = 'hidden'; // Prevent scrolling behind modal
                    }
                });
            });
            
            // Close modal when clicking the close button
            closeModal.addEventListener('click', function() {
                modal.classList.remove('active');
                document.body.style.overflow = ''; // Re-enable scrolling
            });
            
            // Close modal when clicking outside of modal content
            modal.addEventListener('click', function(event) {
                if (event.target === modal) {
                    modal.classList.remove('active');
                    document.body.style.overflow = ''; // Re-enable scrolling
                }
            });
            
            // Close modal with Escape key
            document.addEventListener('keydown', function(event) {
                if (event.key === 'Escape' && modal.classList.contains('active')) {
                    modal.classList.remove('active');
                    document.body.style.overflow = ''; // Re-enable scrolling
                }
            });
            
            // Make "View Certificate" buttons work
            const viewCertificateButtons = document.querySelectorAll('.view-certificate');
            viewCertificateButtons.forEach(button => {
                button.addEventListener('click', function(event) {
                    // Prevent bubbling up to the card click handler
                    event.stopPropagation();
                    
                    // Get the parent card and its ID
                    const card = this.closest('.certificate-card');
                    const certificateId = parseInt(card.getAttribute('data-id'));
                    const certificate = certificatesData.find(cert => cert.id === certificateId);
                    
                    if (certificate) {
                        modalCertificateImg.src = certificate.imgUrl;
                        modalCertificateImg.alt = certificate.title;
                        modalCertificateTitle.textContent = certificate.title;
                        
                        // Check if the reflection contains HTML tags
                        if (certificate.reflection.includes('<p>')) {
                            modalCertificateReflection.innerHTML = certificate.reflection;
                        } else {
                            modalCertificateReflection.textContent = certificate.reflection;
                        }
                        
                        // Show modal with animation
                        modal.classList.add('active');
                        document.body.style.overflow = 'hidden'; // Prevent scrolling behind modal
                    }
                });
            });
        });
    </script>
    <script src="STI.js"></script>
</body>
</html>
